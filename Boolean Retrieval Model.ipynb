{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re \n",
    "import string\n",
    "from nltk.stem import PorterStemmer # built in library for stemming\n",
    "\n",
    "new_data = []\n",
    "stopwords= [\"a\",\"is\",\"the\",\"of\",\"all\",\"and\",\"to\",\"can\",\"be\",\"as\",\"once\",\"for\",\"at\",\"am\",\"are\",\"has\",\n",
    "           \"have\",\"had\",\"up\",\"his\",\"her\",\"in\",\"on\",\"no\",\"we\",\"do\"]\n",
    "PS = PorterStemmer()\n",
    "\n",
    "# This is the function used for preprocessing the text from the documents\n",
    "\n",
    "def PreProcessor_InvertedIndex(data): \n",
    "    DocList = []\n",
    "\n",
    "    # replacing full stops with spaces because \n",
    "    # while tokenization if there is no space between end of one sentence and start of the other sentence\n",
    "    # two different words are tokenized as one\n",
    "    \n",
    "    data = data.replace('.',' ')\n",
    "\n",
    "    #replacing all special characters with spaces to avoid the issues while tokenization\n",
    "\n",
    "    data = data.replace('[',' ')\n",
    "    data = data.replace(']',' ')\n",
    "    data = data.replace(')',' ')\n",
    "    data = data.replace('(',' ')\n",
    "    data = data.replace(':',' ')\n",
    "    data = data.replace(';',' ')\n",
    "    data = data.replace('?',' ')\n",
    "    data = data.replace('\"',' ')\n",
    "    data = data.replace(',',' ')\n",
    "    data = data.replace('!',' ')\n",
    "    data = data.replace('&',' ')\n",
    "    data = data.replace('-',' ')\n",
    "    data = data.replace('$',' ')\n",
    "    data = data.replace('/',' ')\n",
    "    data = data.replace('%',' ')\n",
    "    data = data.replace(\"'\",' ')\n",
    "    data = data.replace('â€”',' ')\n",
    "\n",
    "    #removing punctuation marks\n",
    "\n",
    "    data = data.replace(\"'s\",\" is\")\n",
    "    data = data.replace(\"'ve\",\" have\")\n",
    "    data = data.replace(\"'ll\",\" will\")\n",
    "    data = data.replace(\"'re\",\" are\")\n",
    "    data = data.replace(\"'d\",\" would\")\n",
    "    data = data.replace(\"'m\",\" am\")\n",
    "\n",
    "    #removing notations from the speech \n",
    "\n",
    "    data = data.replace('(ph)',' ')\n",
    "   # data = data.replace('st',' ')\n",
    "   # data = data.replace('nd',' ')\n",
    "    #data = data.replace('rd',' ')\n",
    "    #data = data.replace('th',' ')\n",
    "    \n",
    "    # this function is used to tokenize the string \n",
    "    Data = data.split() \n",
    "\n",
    "    for token in Data :\n",
    "            \n",
    "        #this if condition is used to check if a word is not a stopword\n",
    "        # it also checks that it is not a number\n",
    "    \n",
    "        if token not in stopwords :\n",
    "            if token.isnumeric() is not True :\n",
    "        \n",
    "                # If a word is neither a stopword nor a number , it is casefolded amd passed through porter stemmer \n",
    "                # it is then added to the list of tokens (vocabulary of a document)\n",
    "       \n",
    "                newtoken = token.lower()          # This function implements case folding\n",
    "                stemmedtoken = PS.stem(newtoken)  # This function implements porter stemmer\n",
    "                DocList.append(stemmedtoken)      # List of tokens for each document (vocabulary of a document)\n",
    "                \n",
    "    return DocList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "def PreProcessor_PositionalIndex(data):\n",
    "    DocList = []\n",
    "\n",
    "    # replacing full stops with spaces because \n",
    "    # while tokenization if there is no space between end of one sentence and start of the other sentence\n",
    "    # two different words are tokenized as one\n",
    "    \n",
    "    data = data.replace('.',' ')\n",
    "\n",
    "    #replacing all special characters with spaces to avoid the issues while tokenization\n",
    "\n",
    "    data = data.replace('[',' ')\n",
    "    data = data.replace(']',' ')\n",
    "    data = data.replace(')',' ')\n",
    "    data = data.replace('(',' ')\n",
    "    data = data.replace(':',' ')\n",
    "    data = data.replace(';',' ')\n",
    "    data = data.replace('?',' ')\n",
    "    data = data.replace('\"',' ')\n",
    "    data = data.replace(',',' ')\n",
    "    data = data.replace('!',' ')\n",
    "    data = data.replace('&',' ')\n",
    "    data = data.replace('-',' ')\n",
    "    data = data.replace('$',' ')\n",
    "    data = data.replace('/',' ')\n",
    "    data = data.replace('%',' ')\n",
    "    data = data.replace(\"'\",' ')\n",
    "    data = data.replace('â€”',' ')\n",
    "\n",
    "    #removing punctuation marks\n",
    "\n",
    "    data = data.replace(\"'s\",\" is\")\n",
    "    data = data.replace(\"'ve\",\" have\")\n",
    "    data = data.replace(\"'ll\",\" will\")\n",
    "    data = data.replace(\"'re\",\" are\")\n",
    "    data = data.replace(\"'d\",\" would\")\n",
    "    data = data.replace(\"'m\",\" am\")\n",
    "\n",
    "    #removing notations from the speech \n",
    "\n",
    "    data = data.replace('(ph)',' ')\n",
    "   # data = data.replace('st',' ')\n",
    "   # data = data.replace('nd',' ')\n",
    "    #data = data.replace('rd',' ')\n",
    "    #data = data.replace('th',' ')\n",
    "    \n",
    "    # this function is used to tokenize the string \n",
    "    Data = data.split() \n",
    "\n",
    "    for token in Data :\n",
    "            \n",
    "                # If a word is neither a stopword nor a number , it is casefolded amd passed through porter stemmer \n",
    "                # it is then added to the list of tokens (vocabulary of a document)\n",
    "       \n",
    "                newtoken = token.lower()          # This function implements case folding\n",
    "                stemmedtoken = PS.stem(newtoken)  # This function implements porter stemmer\n",
    "                DocList.append(stemmedtoken)      # List of tokens for each document (vocabulary of a document)\n",
    "                \n",
    "    return DocList"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of the inverted index\n",
    "\n",
    "def InvertedIndex() :\n",
    "    \n",
    "    Inverted_Index = {} #Inverted Index is a dictionary with \"tokens\" as \"keys\" and \"document ids\" as \"key values\" \n",
    "\n",
    "    for file in Dictionary1 : \n",
    "        for word in Dictionary1[file]: \n",
    "            if word not in Inverted_Index.keys(): #checking if the key exists or not \n",
    "                Inverted_Index[word] = [file]     # adding tokens as keys in dictionary\n",
    "            else :\n",
    "                if file not in Inverted_Index[word]:\n",
    "                    Inverted_Index[word].append(file) # adding document ids to the respective keys (tokens)\n",
    "    \n",
    "    return(Inverted_Index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Implementation of the positional index\n",
    "\n",
    "def PositionalIndex() :\n",
    "    \n",
    "    Positional_Index = {} #Positional Index is a dictionary of dictionaries , where a new dictionary is formed for each token \n",
    "                     # in which \"document id\" serves as \"key\" and \"index of token in that document\" serves as \"key values\"\n",
    "\n",
    "    for file in Dictionary2 :                       # returns index of list \n",
    "        for i in range((len(Dictionary2[file]))-1): # returns index of tokens in the list \n",
    "            if Dictionary2[file][i] not in Positional_Index : # checks if the token exists in the positional index\n",
    "                if Dictionary2[file][i].isnumeric()is not True: # digits are not added to the positional index\n",
    "                    Positional_Index[Dictionary2[file][i]] = {}   #asigns a dictionary to each token \n",
    "                    Positional_Index[Dictionary2[file][i]][file] = [i] # the first document id and the index of token \n",
    "                else :\n",
    "                    i += 1 # if its a digit only position counter is incremented\n",
    "            else:\n",
    "                if file not in Positional_Index[Dictionary2[file][i]].keys():#checks if document id exists in the dictionary of token\n",
    "                    Positional_Index[Dictionary2[file][i]][file] = [i] # adds the document id if it's not already preset \n",
    "                else:\n",
    "                    Positional_Index[Dictionary2[file][i]][file].append(i) # appends the index of token in existing document id  \n",
    "\n",
    "    return(Positional_Index)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "FilesInfo = [\"Trump Speechs\\speech_0.txt\",\"Trump Speechs\\speech_1.txt\",\"Trump Speechs\\speech_2.txt\", \n",
    "             \"Trump Speechs\\speech_3.txt\",\"Trump Speechs\\speech_4.txt\",\"Trump Speechs\\speech_5.txt\",\n",
    "             \"Trump Speechs\\speech_6.txt\",\"Trump Speechs\\speech_7.txt\",\"Trump Speechs\\speech_8.txt\",\n",
    "             \"Trump Speechs\\speech_9.txt\",\"Trump Speechs\\speech_10.txt\",\"Trump Speechs\\speech_11.txt\",\n",
    "             \"Trump Speechs\\speech_12.txt\",\"Trump Speechs\\speech_13.txt\",\"Trump Speechs\\speech_14.txt\",\n",
    "             \"Trump Speechs\\speech_15.txt\",\"Trump Speechs\\speech_16.txt\",\"Trump Speechs\\speech_17.txt\",\n",
    "             \"Trump Speechs\\speech_18.txt\",\"Trump Speechs\\speech_19.txt\",\"Trump Speechs\\speech_20.txt\",\n",
    "             \"Trump Speechs\\speech_21.txt\",\"Trump Speechs\\speech_22.txt\",\"Trump Speechs\\speech_23.txt\",\n",
    "             \"Trump Speechs\\speech_24.txt\",\"Trump Speechs\\speech_25.txt\",\"Trump Speechs\\speech_26.txt\",\n",
    "             \"Trump Speechs\\speech_27.txt\",\"Trump Speechs\\speech_28.txt\",\"Trump Speechs\\speech_29.txt\",\n",
    "             \"Trump Speechs\\speech_30.txt\",\"Trump Speechs\\speech_31.txt\",\"Trump Speechs\\speech_32.txt\",\n",
    "             \"Trump Speechs\\speech_33.txt\",\"Trump Speechs\\speech_34.txt\",\"Trump Speechs\\speech_35.txt\",\n",
    "             \"Trump Speechs\\speech_36.txt\",\"Trump Speechs\\speech_37.txt\",\"Trump Speechs\\speech_38.txt\",\n",
    "             \"Trump Speechs\\speech_39.txt\",\"Trump Speechs\\speech_40.txt\",\"Trump Speechs\\speech_41.txt\",\n",
    "             \"Trump Speechs\\speech_42.txt\",\"Trump Speechs\\speech_43.txt\",\"Trump Speechs\\speech_44.txt\",\n",
    "             \"Trump Speechs\\speech_45.txt\",\"Trump Speechs\\speech_46.txt\",\"Trump Speechs\\speech_47.txt\",\n",
    "             \"Trump Speechs\\speech_48.txt\",\"Trump Speechs\\speech_49.txt\",\"Trump Speechs\\speech_50.txt\",\n",
    "             \"Trump Speechs\\speech_51.txt\",\"Trump Speechs\\speech_52.txt\",\"Trump Speechs\\speech_53.txt\",\n",
    "             \"Trump Speechs\\speech_54.txt\",\"Trump Speechs\\speech_55.txt\"]\n",
    "\n",
    "Dictionary1 = {}  # A Dictionary for Inverted Index (without stopwords) to store list of tokens of each document at each index \n",
    "                # i-e list of tokens of document 0 at index 0\n",
    "Dictionary2 = {}  # A Dictionary for Positional Index (with stopwords) to store list of tokens of each document at each index \n",
    "                # i-e list of tokens of document 0 at index 0\n",
    "i=0\n",
    "\n",
    "# The loop below opens each document one by one , reads it into a string\n",
    "# and sends the string to the function for tokenization which returns a list of tokens for each document\n",
    "# and that list is stored into a dictionary\n",
    "\n",
    "for File in FilesInfo:\n",
    "    file=open(File , 'r')\n",
    "    next(file)\n",
    "    data = file.read() #reading the file into a string\n",
    "    Dictionary1[i] = PreProcessor_InvertedIndex(data) # storing the list of each document into a dictionary\n",
    "    i += 1 # this is used for maintaing index of the dictionary\n",
    "  \n",
    "Inverted_Index = InvertedIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The same procedure as above is done for Positional Index\n",
    "\n",
    "i=0\n",
    "\n",
    "for File in FilesInfo:\n",
    "    file=open(File , 'r')\n",
    "    next(file)\n",
    "    data = file.read() #reading the file into a string\n",
    "    Dictionary2[i] = PreProcessor_PositionalIndex(data) # storing the list of each document into a dictionary\n",
    "    i += 1 # this is used for maintaing index of the dictionary\n",
    "    \n",
    "Positional_Index = PositionalIndex()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [],
   "source": [
    "def QueryPreProcessor(query):\n",
    "    \n",
    "    query = query.replace('[',' ')\n",
    "    query = query.replace(']',' ')\n",
    "    query = query.replace(')',' ')\n",
    "    query = query.replace('(',' ')\n",
    "    query = query.replace(':',' ')\n",
    "    query = query.replace(';',' ')\n",
    "    query = query.replace('?',' ')\n",
    "    query = query.replace('\"',' ')\n",
    "    query = query.replace(',',' ')\n",
    "    query = query.replace('!',' ')\n",
    "    query = query.replace('&',' ')\n",
    "    query = query.replace('-',' ')\n",
    "    query = query.replace('$',' ')\n",
    "    query = query.replace('/',' ')\n",
    "    query = query.replace('%',' ')\n",
    "    query = query.replace(\"'\",' ')\n",
    "    query = query.replace('â€”',' ')\n",
    "    query = query.lower() \n",
    "    query = PS.stem(query)\n",
    "    \n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This function solves the simple boolean queries\n",
    "\n",
    "def SimpleBooleanQuery(query):\n",
    "    \n",
    "    query = query.split() # make tokens of the query\n",
    "    operator = 'NULL'\n",
    "    MatchingWordsList = [] #used to store the list of doc id of the tokens that are in the query\n",
    "    EmptyList = []         # used in OR operation \n",
    "    DocList = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "           41,42,43,44,45,46,47,48,49,50,51,52,53,54,55] #used for NOT operation \n",
    "\n",
    "    for token in query: # the query is parsed token by token \n",
    "        if token == 'OR' or token == 'AND' or token == 'NOT' : #checks it the token is a boolean operator \n",
    "            operator = token \n",
    "        else: \n",
    "            token = QueryPreProcessor(token) # if the token is not a boolean operator then it is preprocessed\n",
    "            for word in Inverted_Index:\n",
    "                if token == word:                                  # the token is searched in the inverted index \n",
    "                    MatchingWordsList.append(Inverted_Index[word]) # the list of doc ids of that token is stored \n",
    "\n",
    "    if operator == 'AND':   # AND operation between lists of doc ids \n",
    "        for i in range(len(MatchingWordsList)-1): # loop for retrieving index of a list in MatchingWordsList\n",
    "            if i == 0:\n",
    "                list1 = set(MatchingWordsList[i])\n",
    "                list2 = set(MatchingWordsList[i+1])\n",
    "                res = list1.intersection(list2)\n",
    "            else :\n",
    "                list1 = set(MatchingWordsList[i+1])\n",
    "                list2 = set(res)\n",
    "                res = list1.intersection(list2)\n",
    "        label3 = tk.Label(text= res ,font=('helvetica', 10, 'bold')) # used for printing result in the GUI\n",
    "        label3.place(x=160,y=220)\n",
    "    \n",
    "    elif operator == 'OR' :  # OR operation between lists of doc ids\n",
    "        for i in range(len(MatchingWordsList)-1): # loop for retrieving index of a list in MatchingWordsList\n",
    "            if i == 0:\n",
    "                list1 = set(MatchingWordsList[i])\n",
    "                list2 = set(MatchingWordsList[i+1])\n",
    "                res = list1.union(list2)\n",
    "            else :\n",
    "                list1 = set(MatchingWordsList[i+1])\n",
    "                list2 = set(res)\n",
    "                res = list1.union(list2)\n",
    "        label3 = tk.Label(text= res ,font=('helvetica', 10, 'bold')) # used for printing result in the GUI\n",
    "        label3.place(x=160,y=220)\n",
    "        label3.after(30000 , label3.master.destroy)\n",
    "    \n",
    "    elif operator == 'NOT' :  # NOT operation on the list of doc ids\n",
    "        for List in MatchingWordsList :  # loop for retrieving a list in MatchingWordsList\n",
    "            List = set(DocList) - set(List)\n",
    "            label3 = tk.Label(text= List ,font=('helvetica', 10, 'bold')) # used for printing result in the GUI\n",
    "            label3.place(x=160,y=220)\n",
    "            label3.after(30000 , label3.master.destroy)\n",
    "    \n",
    "    elif operator == 'NULL':            # if the query is a single word query\n",
    "        for List in MatchingWordsList : # loop for retrieving a list in MatchingWordsList\n",
    "            label3 = tk.Label(text= List ,font=('helvetica', 10, 'bold')) # used for printing result in the GUI\n",
    "            label3.place(x=160,y=220)\n",
    "            label3.after(30000 , label3.master.destroy)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This function solves the complex boolean queries\n",
    "\n",
    "def ComplexBooleanQuery(query):\n",
    "    \n",
    "    WordsList = []\n",
    "    List = []\n",
    "    pos=0\n",
    "    DocList = [0,1,2,3,4,5,6,7,8,9,10,11,12,13,14,15,16,17,18,19,20,21,22,23,24,25,26,27,28,29,30,31,32,33,34,35,36,37,38,39,40,\n",
    "           41,42,43,44,45,46,47,48,49,50,51,52,53,54,55] #used for NOT operation\n",
    "\n",
    "    query=query.replace('(','( ')\n",
    "    query=query.replace(')',' )')\n",
    "    query=query.split()\n",
    "\n",
    "     # the loop below solves the query within the round brackets and the result is stored into a variable\n",
    "        \n",
    "    for i in range(len(query)) : \n",
    "        if query[i] == '(' :\n",
    "            pos=i\n",
    "            i+=1\n",
    "            for j in range(i,len(query)-1):\n",
    "                 if query[j] == 'OR' or query[j] == 'AND' or query[j] == 'NOT' : #checks it the token is a boolean operator \n",
    "                    operator = query[j] \n",
    "                 else: \n",
    "                    query[j] = QueryPreProcessor(query[j]) # if the token is not a boolean operator then it is preprocessed\n",
    "                    for word in Inverted_Index:\n",
    "                        if query[j] == word:                                  # the token is searched in the inverted index\n",
    "                            WordsList.append(Inverted_Index[word]) # the list of doc ids of that token is stored \n",
    "\n",
    "            break\n",
    "        \n",
    "    if operator == 'AND':   # AND operation between lists of doc ids \n",
    "            for i in range(len(WordsList)-1): # loop for retrieving index of a list in MatchingWordsList\n",
    "                if i == 0:\n",
    "                    list1 = set(WordsList[i])\n",
    "                    list2 = set(WordsList[i+1])\n",
    "                    res = list1.intersection(list2)\n",
    "                else :\n",
    "                    list1 = set(WordsList[i+1])\n",
    "                    list2 = set(res)\n",
    "                    res = list1.intersection(list2)\n",
    "\n",
    "    elif operator == 'OR' :  # OR operation between lists of doc ids\n",
    "        for i in range(len(WordsList)-1): # loop for retrieving index of a list in MatchingWordsList\n",
    "            if i == 0:\n",
    "                list1 = set(WordsList[i])\n",
    "                list2 = set(WordsList[i+1])\n",
    "                res = list1.union(list2)\n",
    "            else :\n",
    "                list1 = set(WordsList[i+1])\n",
    "                list2 = set(res)\n",
    "                res = list1.union(list2)\n",
    "    \n",
    "    # for AND and OR operations :\n",
    "    \n",
    "    if pos == 2: # this is the position of the operator\n",
    "    \n",
    "        operator = query[1]\n",
    "        query[0]=QueryPreProcessor(query[0])\n",
    "        for word in Inverted_Index:\n",
    "            if query[0] == word:                                \n",
    "                List = Inverted_Index[word]\n",
    "        if operator == 'OR' :  #performs OR operation on the result retrieved from the query in brackets\n",
    "            list1 = set(List)\n",
    "            list2 = set(res)\n",
    "            label3 = tk.Label(text= list1.union(list2) ,font=('helvetica', 10, 'bold')) # used for printing result in the GUI\n",
    "            label3.place(x=160,y=220)\n",
    "            label3.after(5000 , label3.master.destroy)\n",
    "        elif operator == 'AND' : #performs AND operation on the result retrieved from the query in brackets\n",
    "            list1 = set(List)\n",
    "            list2 = set(res)\n",
    "            label3 = tk.Label(text= list1.intersection(list2) ,font=('helvetica', 10, 'bold')) # used for printing result in the GUI\n",
    "            label3.place(x=160,y=220)\n",
    "            label3.after(30000 , label3.master.destroy)\n",
    "            \n",
    "    # for NOT operations :\n",
    "    \n",
    "    #performs NOT operation on the result retrieved from the query in brackets\n",
    "    \n",
    "    elif pos == 1: # this is the position of the operator\n",
    "    \n",
    "        List = set(DocList) - set(res)\n",
    "        label3 = tk.Label(text= List ,font=('helvetica', 10, 'bold')) # used for printing result in the GUI\n",
    "        label3.place(x=160,y=220)\n",
    "        label3.after(30000 , label3.master.destroy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# This function solves proximity queries\n",
    "\n",
    "def ProximityQuery(query):\n",
    "    \n",
    "    MatchingTokensDict = {}  # used to save the posting lists of the matching tokens\n",
    "    DocList = []\n",
    "\n",
    "    query = query.split() \n",
    "\n",
    "    for i in range (len(query)):\n",
    "        query[i] = QueryPreProcessor(query[i])\n",
    "\n",
    "    i = 0\n",
    "\n",
    "    for token in Positional_Index :\n",
    "        if token in query:\n",
    "            MatchingTokensDict[i] = Positional_Index[token]  # the posting list of the matched tokens is saved \n",
    "            i += 1        \n",
    "\n",
    "    i = 0 ; j = 1\n",
    "\n",
    "    for docid in MatchingTokensDict[i]: # iterates through the posting list of the first matched token \n",
    "        for docId in MatchingTokensDict[j]: # iterates through the posting list of the second matched token\n",
    "            if docid == docId: # if doc id in both the posting lists matches \n",
    "                for pos in MatchingTokensDict[i][docid]: # check the position of the token in first document\n",
    "                    for Pos in MatchingTokensDict[j][docId]: # # check the position of the token in second document\n",
    "                        if(len(query)==2): # for queries with no proximity operator \n",
    "                            if pos - Pos == 1: # if both the tokens are \"k\" tokens apart\n",
    "                                if docid not in DocList:\n",
    "                                    DocList.append(docid)  # adds to the list\n",
    "                        else: # for queries with proximity operator \n",
    "                            if pos - Pos == (int(query[len(query)-1]) + 1): # if both the tokens are \"k\" tokens apart\n",
    "                                if docid not in DocList:\n",
    "                                    DocList.append(docid) # adds to the list\n",
    "                                    \n",
    "    label3 = tk.Label(text= DocList ,font=('helvetica', 10, 'bold')) # used for printing result in the GUI\n",
    "    label3.place(x=160,y=220)\n",
    "    label3.after(30000 , label3.master.destroy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# This function receives the query and works on retrieving documents related to the query\n",
    "\n",
    "def MainFunction():\n",
    "    \n",
    "    query = entry1.get()  # \n",
    "\n",
    "    # this condition checks if the query entered is a simple boolean query \n",
    "    # if the query is a single word query or it has a unique boolean opeator\n",
    "    # the query is taken to be a simple boolean query\n",
    "\n",
    "    SimpleBoolean = (('OR' in query and ('AND' not in query and 'NOT' not in query))\n",
    "        or ('AND' in query and ('OR' not in query and 'NOT' not in query))\n",
    "        or ('NOT' in query and ('OR' not in query and 'AND' not in query))\n",
    "        or (len(query.split()) == 1))\n",
    "\n",
    "    # this condition checks if the query entered is a complex boolean query \n",
    "    # if the query has two different boolean operators\n",
    "    # the query is taken to be a complex boolean query\n",
    "\n",
    "    ComplexBoolean=(('OR' in query and 'AND' in query) or ('OR' in query and 'NOT' in query) or ('AND' in query and 'NOT' in query))\n",
    "\n",
    "    # this condition checks if the query entered is a proximity query \n",
    "    # if the query has proximity operator and ends at a digit \n",
    "    # or the query has more than one words with no Boolean Operator\n",
    "    # the query is taken to be a proximity query\n",
    "\n",
    "    Proximity = ('/' in query or (len(query.split()) > 1))\n",
    "    \n",
    "    label2 = tk.Label(text=\"Retrieved Documents : \")\n",
    "    label2.place(x=20,y=220)\n",
    "\n",
    "    if SimpleBoolean:\n",
    "        SimpleBooleanQuery(query)\n",
    "    elif ComplexBoolean:\n",
    "        ComplexBooleanQuery(query)\n",
    "    elif Proximity:\n",
    "        ProximityQuery(query)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This snippet is used for the implementation of GUI \n",
    " \n",
    "# Note : The GUI window automatically closes after 30 sec of displaying output of one query \n",
    "\n",
    "import tkinter as tk\n",
    "\n",
    "win = tk.Tk()\n",
    "win.title(\"Information Retrieval Assignment # 01 \") # used to set the title of the window\n",
    "win.geometry(\"1050x300\")  # used to set the size of the window \n",
    "\n",
    "greeting = tk.Label(text=\"Query Processing Interface\",fg=\"black\",height=2,font=(\"Arial\", 12,\"bold\")) \n",
    "greeting.place(x=435,y=10)  # used to set the position\n",
    "\n",
    "label1 = tk.Label(text=\"Type your query : \") # used to create the input statement\n",
    "entry1 = tk.Entry()  # used to create the input box \n",
    "\n",
    "label1.place(x=500,y=90)  # used to set the position of the input statement\n",
    "entry1.place(x=420,y=120,width=280) # used to set the position of the input box\n",
    "\n",
    "button = tk.Button(text='Find Result', command=MainFunction, bg='brown', fg='white', font=('helvetica', 9, 'bold')) \n",
    "button.place(x=520,y=150)  # used to set the position of the button \n",
    "\n",
    "win.mainloop()"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
